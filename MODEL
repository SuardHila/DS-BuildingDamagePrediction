=================================================================================================================================================================================================================

This project predicts whether a building in district 4 of Nepal suffered severe earthquake damage based on structural features. The data is extracted from a SQLite database and processed using a custom wrangling function.
The model workflow includes:
 * Data preprocessing and feature engineering.
 * Splitting the data into training, validation, and test sets.
 * Building a Decision Tree Classifier with a depth limit.
 * Hyperparameter tuning by testing different tree depths.
 * Evaluating the model on training, validation, and test sets.
 * Visualizing the decision tree and interpreting feature importance.

This analysis helps identify key structural factors linked to severe earthquake damage and builds a model that can support future risk assessments.
=================================================================================================================================================================================================================

target = "severe_damage"
X = df.drop(columns=target)
y = df[target]


X_train, X_test, y_train, y_test = train_test_split(
    X,y,test_size=0.2,random_state=42
)


X_train, X_val, y_train, y_val = train_test_split(
    X_train,y_train,test_size=0.2,random_state=42

)




acc_baseline = y_train.value_counts(normalize=True).max()
print("Baseline Accuracy:", round(acc_baseline, 2))



# Build Model
model = make_pipeline(
    OrdinalEncoder(),
    DecisionTreeClassifier(max_depth=6,random_state=42)
)
# Fit model to training data
model.fit(X_train,y_train)



acc_train = accuracy_score(y_train,model.predict(X_train))
acc_val = model.score(X_val,y_val)


tree_depth = model.named_steps["decisiontreeclassifier"].get_depth()
print("Tree Depth:", tree_depth)


depth_hyperparams = range(1,50,2)


# Create empty lists for training and validation accuracy scores
training_acc = []
validation_acc = []

for d in depth_hyperparams:
    # Create model with `max_depth` of `d`
    test_model =  make_pipeline(
    OrdinalEncoder(),
    DecisionTreeClassifier(max_depth=d,random_state=42)
    )
    # Fit model to training data
    test_model.fit(X_train, y_train)
    # Calculate training accuracy score and append to `training_acc`
    training_acc.append(test_model.score(X_train,y_train))
    # Calculate validation accuracy score and append to `training_acc`
    validation_acc.append(test_model.score(X_val,y_val))

print("Training Accuracy Scores:", training_acc[:3])
print("Validation Accuracy Scores:", validation_acc[:3])



test_acc = model.score(X_test,y_test)
print("Test Accuracy:", round(test_acc, 2))


# Create larger figure
fig, ax = plt.subplots(figsize=(25, 12))
# Plot tree
plot_tree(
    decision_tree=model.named_steps["decisiontreeclassifier"],
    feature_names=X_train.columns.to_list(),
    filled=True,  # Color leaf with class
    rounded=True,  # Round leaf edges
    proportion=True,  # Display proportion of classes in leaf
    max_depth=3,  # Only display first 3 levels
    fontsize=12,  # Enlarge font
    ax=ax,  # Place in figure axis
);



features = X_train.columns
importances = model.named_steps["decisiontreeclassifier"].feature_importances_

print("Features:", features[:3])
print("Importances:", importances[:3])




