=================================================================================================================================================================================================================
Model Training and Evaluation
Data Splitting:
The dataset is split into training and validation sets (80% training, 20% validation) for model evaluation.
Baseline Accuracy:
The baseline accuracy is calculated based on the most frequent value in the target variable (severe_damage), which provides a reference for model performance.
Logistic Regression Model:
A Logistic Regression model is trained on the training data with One-Hot Encoding for categorical variables. The model's accuracy is calculated on both the training and validation sets.
Decision Tree Model:
A Decision Tree Classifier is trained with different max_depth values (from 1 to 15). The model's accuracy is calculated for both training and validation sets to find the optimal depth.
Accuracy Plot:
A plot is generated showing the training and validation accuracy for each depth value to visualize the model's performance and identify the best max_depth that prevents overfitting.
=================================================================================================================================================================================================================


target="severe_damage"
X = df.drop(columns=target)
y = df[target]


X_train, X_val, y_train, y_val = train_test_split(
    X,y,test_size=0.2,random_state=42
)


acc_baseline = y_train.value_counts(normalize=True).max()

model_lr = make_pipeline(
    
    OneHotEncoder(use_cat_names=True),
    LogisticRegression(max_iter=1000)  
    
)


lr_train_acc =  accuracy_score(y_train,model_lr.predict(X_train))
lr_val_acc = model_lr.score(X_val,y_val)





depth_hyperparams = range(1, 16)
training_acc = []
validation_acc = []

for d in depth_hyperparams:
    model_dt = make_pipeline(
        OneHotEncoder(),
        DecisionTreeClassifier(max_depth=d, random_state=42)
    )
    model_dt.fit(X_train, y_train)
    
    
     # Make predictions on the training and validation sets
    y_train_pred = model_dt.predict(X_train)
    y_val_pred = model_dt.predict(X_val)
    
    # Calculate accuracy scores
    train_accuracy = accuracy_score(y_train, y_train_pred)
    val_accuracy = accuracy_score(y_val, y_val_pred)
    
    # Record the scores
    training_acc.append(train_accuracy)
    validation_acc.append(val_accuracy)


validation_acc.index(max(validation_acc)) 

plt.plot(depth_hyperparams,training_acc,label="training")
plt.plot(depth_hyperparams,validation_acc,label="validation")


final_model_dt =  make_pipeline(
        OrdinalEncoder(),
        DecisionTreeClassifier(max_depth=10, random_state=42)
    )
final_model_dt.fit(X_train,y_train)


X_test = pd.read_csv("data/kavrepalanchok-test-features.csv", index_col="b_id")
y_test_pred = final_model_dt.predict(X_test)
y_test_pred[:5]




